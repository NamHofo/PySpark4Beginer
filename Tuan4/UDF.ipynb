{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+----------+----------------+------+\n",
      "|employee_id|            Name|       doj|employee_dept_id|salary|\n",
      "+-----------+----------------+----------+----------------+------+\n",
      "|         10|Michael Robinson|1999-06-01|             100|  2000|\n",
      "|         20|      James Wood|2003-03-01|             200|  8000|\n",
      "|         30|   Chris Andrews|2005-04-01|             100|  6000|\n",
      "|         40|       Mark Bond|2008-10-01|             100|  7000|\n",
      "|         50|    Steve Watson|1996-02-01|             400|  1000|\n",
      "|         60|   Mathews Simon|1998-11-01|             500|  5000|\n",
      "|         70|      Peter Paul|2011-04-01|             600|  5000|\n",
      "+-----------+----------------+----------+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()\n",
    "\n",
    "employee_data = [\n",
    "    (10, \"Michael Robinson\", \"1999-06-01\", \"100\", 2000),\n",
    "    (20, \"James Wood\", \"2003-03-01\", \"200\", 8000),\n",
    "    (30, \"Chris Andrews\", \"2005-04-01\", \"100\", 6000),\n",
    "    (40, \"Mark Bond\", \"2008-10-01\", \"100\", 7000),\n",
    "    (50, \"Steve Watson\", \"1996-02-01\", \"400\", 1000),\n",
    "    (60, \"Mathews Simon\", \"1998-11-01\", \"500\", 5000),\n",
    "    (70, \"Peter Paul\", \"2011-04-01\", \"600\", 5000)\n",
    "]\n",
    "\n",
    "employee_schema = [\"employee_id\", \"Name\", \"doj\", \"employee_dept_id\", \"salary\"]\n",
    "\n",
    "empDF = spark.createDataFrame(data=employee_data, schema=employee_schema) \n",
    "\n",
    "empDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define UDF to Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "\n",
    "def rename_columns(rename_df):\n",
    "    for column in rename_df.columns:\n",
    "        new_column = \"Col_\"+column\n",
    "        rename_df = rename_df.withColumnRenamed(column, new_column)\n",
    "    return rename_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------+----------+--------------------+----------+\n",
      "|Col_employee_id|        Col_Name|   Col_doj|Col_employee_dept_id|Col_salary|\n",
      "+---------------+----------------+----------+--------------------+----------+\n",
      "|             10|Michael Robinson|1999-06-01|                 100|      2000|\n",
      "|             20|      James Wood|2003-03-01|                 200|      8000|\n",
      "|             30|   Chris Andrews|2005-04-01|                 100|      6000|\n",
      "|             40|       Mark Bond|2008-10-01|                 100|      7000|\n",
      "|             50|    Steve Watson|1996-02-01|                 400|      1000|\n",
      "|             60|   Mathews Simon|1998-11-01|                 500|      5000|\n",
      "|             70|      Peter Paul|2011-04-01|                 600|      5000|\n",
      "+---------------+----------------+----------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rename_df = rename_columns(empDF)\n",
    "rename_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDF to convert name into upper case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,upper\n",
    "\n",
    "def upper_case(df):\n",
    "    em_up = df.withColumn(\"Name\", upper(df.Name))\n",
    "    return em_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+----------+----------------+------+\n",
      "|employee_id|            Name|       doj|employee_dept_id|salary|\n",
      "+-----------+----------------+----------+----------------+------+\n",
      "|         10|MICHAEL ROBINSON|1999-06-01|             100|  2000|\n",
      "|         20|      JAMES WOOD|2003-03-01|             200|  8000|\n",
      "|         30|   CHRIS ANDREWS|2005-04-01|             100|  6000|\n",
      "|         40|       MARK BOND|2008-10-01|             100|  7000|\n",
      "|         50|    STEVE WATSON|1996-02-01|             400|  1000|\n",
      "|         60|   MATHEWS SIMON|1998-11-01|             500|  5000|\n",
      "|         70|      PETER PAUL|2011-04-01|             600|  5000|\n",
      "+-----------+----------------+----------+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "upper_df = upper_case(empDF)\n",
    "upper_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
